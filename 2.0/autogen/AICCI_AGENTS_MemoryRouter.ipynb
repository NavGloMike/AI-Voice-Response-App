{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ba49f59-e8f5-49f1-abb0-8b8ab8117165",
   "metadata": {},
   "source": [
    "## AI-powered Contact Center Intake (AICCI) Agents - Memory/Router Design\n",
    "\n",
    " * Author:    Kyle Zarifsadr\n",
    " * Created:   January 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1ec7c8-3c97-4edb-ac62-78b4971cd03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import openai\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "from openai import AzureOpenAI\n",
    "import psycopg\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import autogen\n",
    "from autogen import GroupChat\n",
    "from autogen import GroupChatManager\n",
    "from autogen import AssistantAgent\n",
    "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
    "from autogen import ConversableAgent, UserProxyAgent, config_list_from_json\n",
    "from autogen.retrieve_utils import TEXT_FORMATS\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "from pgvector.psycopg2 import register_vector\n",
    "from autogen import AssistantAgent, ConversableAgent, UserProxyAgent\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ea828a-ff13-4a56-8397-bc7b3fc6dd6d",
   "metadata": {},
   "source": [
    "# LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db10a6cc-96de-49b9-ab45-3721655a1154",
   "metadata": {},
   "source": [
    "### Azure OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90479f01-2020-41da-af06-5151f1e6298e",
   "metadata": {},
   "source": [
    "Reference: https://microsoft.github.io/autogen/0.2/docs/reference/agentchat/contrib/vectordb/pgvectordb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438f7a80-f860-4fad-b064-e29c5a05b4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"gpt-4o\",\n",
    "            \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "            \"api_type\": \"azure\",\n",
    "            \"base_url\": os.getenv(\"OPENAI_API_BASE\"),\n",
    "            \"api_version\": os.getenv(\"API_VERSION\"),\n",
    "        },\n",
    "    ],\n",
    "    \"temperature\": 0.0,\n",
    "    \"timeout\": 300,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88149d65-2a9a-40df-8a2a-cbdcd6ac392a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  \n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "azure_endpoint = os.getenv(\"OPENAI_API_BASE\")\n",
    "api_version = os.getenv(\"API_VERSION\")\n",
    "model = \"gpt-4o\"\n",
    "temprature = 0.0\n",
    "top_p = 1.0\n",
    "\n",
    "def get_response_client(template, text, temprature=temprature, top_p=top_p, model=model, azure_endpoint=azure_endpoint, api_key=api_key, api_version=api_version):\n",
    "    time.sleep(1)\n",
    "\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint = azure_endpoint, \n",
    "        api_key= api_key,  \n",
    "        api_version= api_version\n",
    "    )\n",
    "\n",
    "    conversation = [\n",
    "        {\"role\": \"system\", \"content\": template},\n",
    "        {\"role\": \"user\", \"content\": text},\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=temprature,\n",
    "        top_p= top_p,\n",
    "        max_tokens=4000,\n",
    "        response_format={ \"type\": \"json_object\" },  #JSON mode\n",
    "        messages=conversation\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b905cd-38e2-4977-8e2e-f68ce2db8cf6",
   "metadata": {},
   "source": [
    "# Knowledge Base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909a04a4-0c8e-4c66-9d1c-f8707a5cebcc",
   "metadata": {},
   "source": [
    "### Simulated API Calls to PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc9cea6-422f-481e-973d-b81104093e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_connection():\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"test\",\n",
    "        user=\"postgres\",\n",
    "        password=\"test_password\",\n",
    "        host=\"localhost\",\n",
    "        port=\"5433\"\n",
    "    )\n",
    "    return conn\n",
    "\n",
    "def make_request(url, clientKey):\n",
    "    conn = get_db_connection()\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    query = \"SELECT response_data FROM guidelines WHERE url = %s AND clientKey = %s;\"\n",
    "    cur.execute(query, (url, clientKey))\n",
    "    result = cur.fetchone()\n",
    "    \n",
    "    if result:\n",
    "        response_data = result[0]\n",
    "        print(f\"Response from {url}: {json.dumps(response_data)}\")\n",
    "        return response_data\n",
    "    #     store_request_response(url, params, response_data)\n",
    "    # else:\n",
    "    #     print(f\"No data found for URL: {url}\")\n",
    "    #     store_request_response(url, params, {\"error\": \"Not Found\"})\n",
    "    \n",
    "    cur.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974fc204-377b-454f-8985-aa3740df815d",
   "metadata": {},
   "source": [
    "### Test clientKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce000f7-e2ea-4414-af18-c1f790026067",
   "metadata": {},
   "outputs": [],
   "source": [
    "clientKey = 'Call Center Training 32 - Target Corporation'  # [ 'Call Center Training 32 - Target Corporation' ,'Call Center Training 31 - UPS', 'StarSpaces', 'BankCorp', 'HealthCarePlus', 'EduCare',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c6b1a4-70d9-4618-9298-9565b7d023da",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"/v6.0/Intake/guidelines\"\n",
    "guidelines = make_request(url, clientKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985ae1ba-c0b6-4195-8b13-997d01b8bc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"/v6.0/Intake/locations\"\n",
    "locations = make_request(url, clientKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce709dd6-0c5b-41bf-90ce-90f4e8022292",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"/v6.0/Intake/GetMobileIssueTypesWithDefaults\"\n",
    "IssueTypes = make_request(url, clientKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d955ee37-79fc-40e8-8a45-4e0103550f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"/v6.0/ViolationQuestion/GetViolationQuestionAndAnswersForPlatformPackages\"\n",
    "questions = make_request(url, clientKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03953fbc-5dcf-4773-9e6a-035f5bd942e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Should be added to the DB\n",
    "implicated_parties = {\"Affected Party\":\"\",\"Perpetrator\":\"\",\"Witness\":\"\",\"Other\":\"\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d56e313-5ee1-4547-a39b-304b4926b5dd",
   "metadata": {},
   "source": [
    "# AGENTIC DESIGN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7355c79-57a1-4872-a719-9bc1e0c35ab1",
   "metadata": {},
   "source": [
    "### 0. Router and Memory Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d05eea-b08c-4030-a903-690b4f3bf3c1",
   "metadata": {},
   "source": [
    "Design Consideration: \n",
    "Track past interactions and select which group chat should be involved next\n",
    " - metadata for each group chat \n",
    " - agent priorities\n",
    " - memory access to past conversation\n",
    " - user intent\n",
    " - termination requirement for each group chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bbd67f-2e29-4ce8-93ee-63a522caa46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_memory = \"\"\"\n",
    "Role: JSON Chat Memory: You will be given a new message and a JSON Chat Memory.\n",
    "Your primary responsibility is to memorize the new message and the JSON Chat Memory.\n",
    "You will take to action!\n",
    "\n",
    "Do not wrap the output in quotation marks.\n",
    "Do not wrap the output in code block delimiters (```).\n",
    "\"\"\"\n",
    "\n",
    "template_router = \"\"\"\n",
    "Role: You are a classification agent. \n",
    "Objective: You will be given the caller's new message, {{JSON Chat Memory}}, {{group_chat}} priorities, and applicable {{group_chat}}'s {{Termination Requirements}}. \n",
    "Your primary responsibility is to detect the the action id for the new message to route to by checking the {{JSON Chat Memory}} against the applicable {{Termination Requirements}} \n",
    "and determine the next {{group_chat}} only from the following {{group_chat}} options.\n",
    "\n",
    "{\n",
    "  \"group_chat\": \n",
    "  [\n",
    "    {\"id\": \"main_imminent_issue\",\n",
    "    \"priority\": 1, \n",
    "    \"role\": \"This function is used when AI detects imminent issue\",\n",
    "    \"termination_requirements\": {\n",
    "        \"requirement_1\": \"presence of imminent issue event in context\",\n",
    "      }\n",
    "    },\n",
    "    {\"id\": \"main_guidelines\",\n",
    "    \"priority\": 2, \n",
    "    \"role\": \"This function is used when the JSON Chat Memory does not contain the customer's responses to the READ messages in guidelines/instructions.\",\n",
    "    \"termination_requirements\": {\n",
    "        \"requirement_1\": \"Answer to all READ Messages\",\n",
    "        \"requirement_2\": \"Have identified the caller's intent to call, whether it is a new report or a follow-up.\"\n",
    "      }\n",
    "    },\n",
    "    {\"id\": \"main_locations\",\n",
    "    \"priority\": 3, \n",
    "    \"role\": \"This function is used when the JSON Chat Memory does not contain the customer responses to the location indentification requirements.\",\n",
    "    \"termination_requirements\": {\n",
    "        \"requirement_1\": \"Respond to all location-related inquiries\", \n",
    "        \"requirement_2\": \"Identify the State, City, and Building details.\"\n",
    "      }\n",
    "    },\n",
    "    {\"id\": \"main_anonymous_mode\",\n",
    "    \"priority\": 4, \n",
    "    \"role\": \"This function is used when the JSON Chat Memory does not contain the customer responses to the report mode requirements.\",\n",
    "    \"termination_requirements\": {\n",
    "        \"requirement_1\": \"The status of Report Mode is being collected and stored in memory.\",\n",
    "        \"requirement_2\":\"if \"Report Mode\" in content: report_mode_value = content[\"Report Mode\"]\",\n",
    "      }\n",
    "    },\n",
    "    {\"id\": \"main_issue_questions\",\n",
    "    \"priority\": 5, \n",
    "    \"role\": \"This function is used when input message is the transcription of the event.\",\n",
    "    \"termination_requirements\": {\n",
    "        \"requirement_1\": \"transcription of the report which is the primary reason for the call is in memory\"\n",
    "      }\n",
    "    },\n",
    "    {\"id\": \"main_issue_questions_follow_up\",\n",
    "    \"priority\": 6, \n",
    "    \"role\": \"This function is used when the JSON Chat Memory does not contain the customer responses to the issue questions\",\n",
    "    \"termination_requirements\": {\n",
    "        \"requirement_1\": \"Answer to all retrieved violation type questions.\"\n",
    "      }\n",
    "    },\n",
    "    {\"id\": \"main_implicated_parties\",\n",
    "    \"priority\": 7, \n",
    "    \"role\": \"This function is used when the JSON Chat Memory does not contain the customer responses to the issue questions\",\n",
    "    \"termination_requirements\": {\n",
    "        \"requirement_1\": \"Information of implicated parties including their names\",\n",
    "        \"requirement_2\": \"Information of implicated parties including their roles\",\n",
    "        \"requirement_3\": \"Information of implicated parties including their job titles\"\n",
    "      }\n",
    "    },\n",
    "    {\"id\": \"main_final_allegation\",\n",
    "    \"priority\": 8, \n",
    "    \"role\": \"This function is used when the JSON Chat Memory does not contain a reevaluation of the \"ViolationTypeId\" after the initial one.\",\n",
    "    \"termination_requirements\": {\n",
    "        \"requirement_1\": \"Information of the presence of \"ViolationTypeId\" for the second time in memory after implicated parties\",\n",
    "      }\n",
    "    },\n",
    "    {\"id\": \"main_report_review\",\n",
    "    \"priority\": 9, \n",
    "    \"role\": \"This function is used when the JSON Chat Memory does not contain the report summary read by the reporter.\",\n",
    "    \"termination_requirements\": {\n",
    "        \"requirement_1\": \"Information of reviewing the summary of the report.\",\n",
    "      }\n",
    "    },  \n",
    "    {\"id\": \"terminate_chat\",\n",
    "    \"priority\": 10, \n",
    "    \"role\": \"This function is used when the JSON Chat Memory does contain the customer responses to the previous priorities.\",\n",
    "    \"termination_requirements\": {\n",
    "        \"requirement_1\": \"Answer to all questions\"\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "If the {{Termination Requirements}} are satisfied, your detected action will be terminate_chat and you are Done!.\n",
    "\n",
    "example: \n",
    "\n",
    "{\"action\":\"main_issue_questions\"}\n",
    "\n",
    "Do not wrap the output in quotation marks.\n",
    "Do not wrap the output in code block delimiters (```).\n",
    "\"\"\"\n",
    "\n",
    "template_imminent_issue = \"\"\"\n",
    "At any point during the interview, AI detects imminent issue and flags report with priority with this message: {\"Final Message\":\"Flag report with priority\"}\n",
    "At any point during the interview, (If suicide ideations deteted, transfer call to CS workflow) with this message: {\"Final Message\":\"transfer call to CS workflow\"}\n",
    "\n",
    "Examples:\n",
    "Threats of Violence: Reports of threats of physical harm or violence from coworkers, supervisors, or customers.\n",
    "Harassment or Assault: Incidents of sexual harassment, physical assault, or severe bullying.\n",
    "Medical Emergencies: Situations involving severe health issues such as heart attacks, severe allergic reactions, or injuries.\n",
    "Unsafe Working Conditions: Immediate dangers due to unsafe conditions like hazardous materials, lack of safety equipment, or structural hazards.\n",
    "Fire or Explosion: Reports of fires, explosions, or similar emergencies posing immediate threats to safety.\n",
    "Active Shooter or Hostage Situation: Incidents involving an active shooter or hostage situation within the workplace.\n",
    "Severe Psychological Distress: Cases of severe psychological distress or suicidal thoughts/intentions.\n",
    "\n",
    "(If suicide ideations deteted, transfer call to CS workflow) with this message: \"transfer call to CS workflow\"\n",
    "\n",
    "Do not wrap the output in quotation marks.\n",
    "Do not wrap the output in code block delimiters (```).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6c9f6b-0a62-4de1-861f-1cd7232f3319",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"memory.json\", \"w\") as json_file:\n",
    "    json.dump([], json_file)\n",
    "\n",
    "def load_chat_history():\n",
    "    with open(\"memory.json\", \"r\") as json_file:\n",
    "        chat_history_data = json.load(json_file)\n",
    "    return chat_history_data\n",
    "\n",
    "chat_history = load_chat_history()\n",
    "print(\"Initial chat history:\", chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d98e4c6-d9d2-4dec-a236-642fa3d31063",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_agent = ConversableAgent(\n",
    "    name=\"memory_agent\",\n",
    "    system_message= f\"{template_memory} + chat history: {chat_history}\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode= \"NEVER\",\n",
    ")\n",
    "\n",
    "router_agent = ConversableAgent(\n",
    "    name=\"router_agent\",\n",
    "    system_message= f\"{template_router} + guidelines instructions: {guidelines}\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode= \"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561a6ed5-b4a2-4bfa-b202-280f64250d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_transition_router(last_speaker, groupchat):\n",
    "    messages = groupchat.messages\n",
    "\n",
    "    if last_speaker is memory_agent:\n",
    "        return router_agent\n",
    "    elif last_speaker is router_agent:\n",
    "        return None\n",
    "\n",
    "groupchat_router = autogen.GroupChat(\n",
    "    agents=[memory_agent,\n",
    "            router_agent\n",
    "           ],\n",
    "    messages=[],\n",
    "    max_round=10,\n",
    "    speaker_selection_method=state_transition_router,\n",
    ")\n",
    "\n",
    "manager_router = autogen.GroupChatManager(groupchat=groupchat_router, llm_config=llm_config)\n",
    "\n",
    "# # Test\n",
    "# last_message = chat_history\n",
    "# history = memory_agent.initiate_chat(recipient=manager_router, message=str(last_message))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2933edd0-0f7e-4a23-8353-6dc9fda73601",
   "metadata": {},
   "source": [
    "### 1. Process Guidelines Data\n",
    "Tagging and Parsing Approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1002ce9-843a-4430-a3d5-d37846488e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_process_guidelines = \"\"\"\n",
    "Extract text in JSON from text or HTML elements similar to the following:\n",
    "\n",
    "{\n",
    "  \"OPENING\": \"Text from opening HTML element\",\n",
    "  \"READ\": {\n",
    "    \"READ_1\": \"1st Text to read\",\n",
    "    \"READ_2\": \"2nd Text to read\",\n",
    "  },\n",
    "  \"DONT_READ\": {\n",
    "    \"DONT_READ_1\": \"1st Text not to read\",\n",
    "    \"DONT_READ_2\": \"2nd Text not to read\",\n",
    "  },\n",
    "  \"Other_Instructions\": {\n",
    "    \"new_report\": \"Other instructions for new report\",\n",
    "    \"follow_up\": \"Other instructions for follow-up\"\n",
    "  }\n",
    "}\n",
    "\n",
    "Do not wrap the output in quotation marks.\n",
    "Do not wrap the output in code block delimiters (```).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d8d611-d7c8-49e9-80b5-466d0e25e0ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "guidelines = get_response_client(template_process_guidelines, guidelines)\n",
    "guidelines = json.loads(guidelines)\n",
    "print(guidelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85d04ed-4d61-40a4-8afe-f676fc45a29c",
   "metadata": {},
   "source": [
    "### 2. Imminent Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44c740b-bf19-4962-ac66-ec21ce82f578",
   "metadata": {},
   "source": [
    "#### 2.a. Imminent Issues: Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fec5e2-a4f1-489a-a9bb-b6b50118023b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = ConversableAgent(\n",
    "    name=\"user_agent\",\n",
    "    system_message= f\"You are an assistant\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode= \"NEVER\",\n",
    ")\n",
    "\n",
    "imminent_issue_agent = ConversableAgent(\n",
    "    name=\"imminent_issue_agent\",\n",
    "    system_message= f\"Imminent Issues: {template_imminent_issue}\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode= \"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bbbacc-6b81-4b7d-a301-5b21ea7082ec",
   "metadata": {},
   "source": [
    "#### 2.b. Imminent Issues: Group Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91149aaf-c815-4ed6-afd6-5408708d90ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_transition_imminent_issue(last_speaker, groupchat):\n",
    "    messages = groupchat.messages\n",
    "\n",
    "    if last_speaker is user_agent:\n",
    "        return imminent_issue_agent\n",
    "    elif last_speaker is imminent_issue_agent:\n",
    "        return None\n",
    "\n",
    "groupchat_imminent_issue = autogen.GroupChat(\n",
    "    agents=[user_agent,\n",
    "            imminent_issue_agent\n",
    "           ],\n",
    "    messages=[],\n",
    "    max_round=20,\n",
    "    speaker_selection_method=state_transition_imminent_issue,\n",
    ")\n",
    "\n",
    "manager_imminent_issue = autogen.GroupChatManager(groupchat=groupchat_imminent_issue, llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818720e5-d798-499d-8bb6-22c680eda04e",
   "metadata": {},
   "source": [
    "#### 2.c. Imminent Issues: Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269e795e-3612-4952-89d2-b633af3c7efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_imminent_issue():\n",
    "    memory = read_chat_history()\n",
    "    memory.append(new_message)\n",
    "\n",
    "    last_message = json.dumps(memory)\n",
    "\n",
    "    user_agent.initiate_chat(recipient=manager_imminent_issue, message=last_message, clear_history=False)\n",
    "    messages_json = manager_imminent_issue.messages_to_string(manager_imminent_issue.groupchat.messages)\n",
    "\n",
    "    new_messages = json.loads(messages_json)\n",
    "    memory.extend(new_messages)\n",
    "\n",
    "    write_chat_history(memory)\n",
    "    extract_and_print_questions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7c55d0-d5cf-4a2d-acf9-c3d3ac42b84c",
   "metadata": {},
   "source": [
    "### 3. Guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab11d5e-8266-439e-b7c9-86904c4f3719",
   "metadata": {},
   "source": [
    "#### 3.a. Guidelines: Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c31fd03-9505-47ab-91cd-65b3dd7f30d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_guidelines = \"\"\"\n",
    "Role: Ethics and Compliance Contact Center Agent\n",
    "Objective: You will be given the callers [previous_chat_history] and applicable [guidelines]. \n",
    "Your primary responsibility is to determine the call reasons \"New Report\"/ \"Follow-Up\" after gathering all answers to the [guidelines] READ messages in a valid JSON.\n",
    "\n",
    "Don't repeat the content of the previous_chat_history.\n",
    "Under no circumstances determine the call reasons if you don't have an answer to the READ messages/questions.\n",
    "Your response should consist of only one question at a time retrieved from the READ messages/questions.\n",
    "You will categorize the call as either a new report or a follow-up on an existing case.\n",
    "\n",
    "Call Reasons:\n",
    "New Report: The caller is calling to file a new report.\n",
    "Follow-Up: The caller is calling to follow up on an existing case.\n",
    "\n",
    "Steps to Determine Call Reason:\n",
    "Always start with the \"Opening\" text from the [guidelines]. check if the \"Opening\" statement has already been used in the current session \n",
    "and then proceed to the next relevant READ messages.\n",
    "\n",
    "Do not wrap the output in quotation marks.\n",
    "Do not wrap the output in code block delimiters (```).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7d7fa5-f816-4268-9dc1-4e2e7325d749",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = ConversableAgent(\n",
    "    name=\"user_agent\",\n",
    "    system_message= f\"You are an assistant\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode= \"NEVER\",\n",
    ")\n",
    "\n",
    "guidelines_agent = ConversableAgent(\n",
    "    name=\"guidelines_agent\",\n",
    "    system_message= f\"Report Datetime: {template_guidelines} + guidelines: {guidelines}\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode= \"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21ecb7e-1eea-4462-a051-1b797a7d18de",
   "metadata": {},
   "source": [
    "#### 3.b. Guidelines: Group Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de31d145-53d5-4158-95db-83ae262c27aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_transition_guidelines(last_speaker, groupchat):\n",
    "    messages = groupchat.messages\n",
    "\n",
    "    if last_speaker is user_agent:\n",
    "        return guidelines_agent\n",
    "    elif last_speaker is guidelines_agent:\n",
    "        return None\n",
    "\n",
    "groupchat_guidelines = autogen.GroupChat(\n",
    "    agents=[user_agent,\n",
    "            guidelines_agent\n",
    "           ],\n",
    "    messages=[],\n",
    "    max_round=20,\n",
    "    speaker_selection_method=state_transition_guidelines,\n",
    ")\n",
    "\n",
    "manager_guidelines = autogen.GroupChatManager(groupchat=groupchat_guidelines, llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a42a327-2956-464a-a542-b09852f924dd",
   "metadata": {},
   "source": [
    "#### 3.c. Guidelines: Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8101d9ec-c8ce-4003-9abf-7263c521adba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_json_data():\n",
    "    follow_ups = {}\n",
    "    while not follow_ups:\n",
    "        user_input = input('Please provide data in JSON format (e.g. {\"key\": \"value\"} or {\"key1\": \"value1\", \"key2\": \"value2\"}): ')\n",
    "        try:\n",
    "            user_data = json.loads(user_input)\n",
    "            if isinstance(user_data, dict):\n",
    "                follow_ups.update(user_data)\n",
    "            else:\n",
    "                print(\"The JSON input must be an object (key-value pairs). Please try again.\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Invalid JSON input. Please try again.\")\n",
    "    return follow_ups\n",
    "\n",
    "def extract_questions_from_memory(memory):\n",
    "    last_message = memory[-1]\n",
    "    content = last_message[\"content\"]\n",
    "\n",
    "    try:\n",
    "        content_dict = json.loads(content)\n",
    "        return content_dict\n",
    "    except json.JSONDecodeError:\n",
    "        questions = [q.strip() + \"?\" if not q.strip().endswith(\"?\") else q.strip() for q in content.split(\"\\n\") if q.strip()]\n",
    "        questions_dict = {q: \"\" for q in questions}\n",
    "        # return questions_dict\n",
    "        return json.dumps(questions_dict)\n",
    "\n",
    "def read_chat_history():\n",
    "    try:\n",
    "        with open(\"memory.json\", \"r\") as json_file:\n",
    "            try:\n",
    "                return json.load(json_file)\n",
    "            except json.JSONDecodeError:\n",
    "                return []  \n",
    "    except FileNotFoundError:\n",
    "        return [] \n",
    "\n",
    "def extract_and_print_questions():\n",
    "    memory = read_chat_history()\n",
    "    questions = extract_questions_from_memory(memory)\n",
    "    print(questions)\n",
    "\n",
    "def write_chat_history(chat_history_data):\n",
    "    seen = set()\n",
    "    unique_messages = []\n",
    "\n",
    "    for message in chat_history_data:\n",
    "        message_str = json.dumps(message, sort_keys=True, ensure_ascii=False)  \n",
    "        if message_str not in seen:\n",
    "            seen.add(message_str)\n",
    "            unique_messages.append(message)\n",
    "\n",
    "\n",
    "    with open(\"memory.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(unique_messages, json_file, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406f16b1-f1c5-45c1-ad02-c3d86020c835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_guidelines(new_message):\n",
    "    memory = read_chat_history()\n",
    "    memory.append(new_message)\n",
    "\n",
    "    last_message = json.dumps(new_message)\n",
    "\n",
    "    user_agent.initiate_chat(recipient=manager_guidelines, message=last_message, clear_history=False)\n",
    "    messages_json = manager_guidelines.messages_to_string(manager_guidelines.groupchat.messages)\n",
    "\n",
    "    new_messages = json.loads(messages_json)\n",
    "    memory.extend(new_messages)\n",
    "\n",
    "    write_chat_history(memory)\n",
    "    extract_and_print_questions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa5a177-101f-4179-b0be-73e6915478a6",
   "metadata": {},
   "source": [
    "### 4. Locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8c14ae-d4f5-4f45-9432-f22ba52813e4",
   "metadata": {},
   "source": [
    "#### 4.a. Locations: Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080272f3-5850-4edb-b8be-251d8252a57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_locations = \"\"\"\n",
    "Retrieve the location of the event from [locations] by asking a few questions one by one about the state, city, etc., \n",
    "using [locations] data.\n",
    "\n",
    "Do not repeat questions with the same context.\n",
    "\n",
    "As soon as you detect the location from [locations], respond with a question to confirm \"Case_CompanyLocation\": \"\", \n",
    "and \"Case_CompanyCity\": \"\" , and  \"Case_CompanyLocation\":\"\" from the data package available in [locations]. \n",
    "\n",
    "Your final question would be to confirm the location of the event. \n",
    "\n",
    "Example: \n",
    "\n",
    "\"Could you please confirm if the event took place in Austin, Texas, in Building D?\"\n",
    "\n",
    "Do not wrap the output in quotation marks.\n",
    "Do not wrap the output in code block delimiters (```).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c74206-3540-4323-bd25-004b57eeaf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_agent = ConversableAgent(\n",
    "    name=\"locations\",\n",
    "    system_message= f\"locations: {locations} + {template_locations}\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode= \"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2396e30-3a00-4fdb-a039-746b63c067a7",
   "metadata": {},
   "source": [
    "#### 4.b. Locations: Group Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185012db-b874-4500-ae86-6dcd8fc617f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_transition_locations(last_speaker, groupchat):\n",
    "    messages = groupchat.messages\n",
    "\n",
    "    if last_speaker is user_agent:\n",
    "        return locations_agent\n",
    "    elif last_speaker is locations_agent:\n",
    "        return None\n",
    "\n",
    "groupchat_locations = autogen.GroupChat(\n",
    "    agents=[user_agent,\n",
    "            locations_agent\n",
    "           ],\n",
    "    messages=[],\n",
    "    max_round=10,\n",
    "    speaker_selection_method=state_transition_locations,\n",
    ")\n",
    "\n",
    "manager_locations = autogen.GroupChatManager(groupchat=groupchat_locations, llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3143ec3a-6683-4320-a3ff-67d52deb73f3",
   "metadata": {},
   "source": [
    "#### 4.c. Locations: Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c60f2f7-ad9a-407b-a53e-41bd290e2b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_locations(new_message):\n",
    "    memory = read_chat_history()\n",
    "    memory.append(new_message)\n",
    "   \n",
    "    last_message = json.dumps(new_message)\n",
    "\n",
    "    user_agent.initiate_chat(recipient=manager_locations, message=last_message, clear_history=False)\n",
    "    messages_json = manager_locations.messages_to_string(manager_locations.groupchat.messages)\n",
    "\n",
    "    new_messages = json.loads(messages_json)\n",
    "    memory.extend(new_messages)\n",
    "\n",
    "    write_chat_history(memory)\n",
    "    extract_and_print_questions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377d635a-0ae3-4037-b07f-f2008634c626",
   "metadata": {},
   "source": [
    "### 5. Report Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d142747-dbac-4bea-a3a9-7398439a4e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_report_mode = \"\"\"\n",
    "Detect the report mode based on the answer you receive. Your answer should be \n",
    "a valid JSON with \"Report Mode\" as the key and the detected report mode, either \"Anonymous\" or \"Non-Anonymous,\" as the value.\n",
    "\n",
    "Example:\n",
    "1. {\"Report Mode\":\"Anonymous\"}\n",
    "2. {\"Report Mode\":\"Non-Anonymous\"}\n",
    "\n",
    "Do not wrap the output in quotation marks.\n",
    "Do not wrap the output in code block delimiters (```).\n",
    "\"\"\"\n",
    "\n",
    "template_anonymous_mode = \"\"\"You are reviewing reports submitted by employees at a company who wish to submit their report anonymously. Please read through the report and\n",
    "only remove any of the person writing the reports personal information, such as their phone number, email address, name, location (such as\n",
    "office number or desk/cubicle/work location which would identify the reporter), race, job title, length of employment, disabilities or gender.\n",
    "Information about people they witnessed should remain. The report should retain as much of the original text as possible without giving identifying\n",
    "details about the person reporting it.\n",
    "\n",
    "Example1: \"I am the only female/engineer in the office/location\" should be removed.\n",
    "Example2: \"The colleague from Marketing, who often sits two desks away from me\" should be changed to \"The colleague from Marketing\".\n",
    "Do not wrap the output in quotation marks.\n",
    "Do not wrap the output in code block delimiters (```).\n",
    "\"\"\"\n",
    "\n",
    "anonymous_mode_agent = ConversableAgent(\n",
    "    name=\"anonymous_mode\",\n",
    "    system_message= template_report_mode,\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode= \"NEVER\",\n",
    ")\n",
    "\n",
    "def state_transition_anonymous_mode(last_speaker, groupchat):\n",
    "    messages = groupchat.messages\n",
    "\n",
    "    if last_speaker is user_agent:\n",
    "        return anonymous_mode_agent\n",
    "    elif last_speaker is anonymous_mode_agent:\n",
    "        return None\n",
    "\n",
    "groupchat_anonymous_mode = autogen.GroupChat(\n",
    "    agents=[user_agent,\n",
    "            anonymous_mode_agent\n",
    "           ],\n",
    "    messages=[],\n",
    "    max_round=10,\n",
    "    speaker_selection_method=state_transition_anonymous_mode,\n",
    ")\n",
    "\n",
    "manager_anonymous_mode = autogen.GroupChatManager(groupchat=groupchat_anonymous_mode, llm_config=llm_config)\n",
    "\n",
    "def collect_anonymous_mode():\n",
    "    system_default_note = \"Do you wish to provide your name today, or would you rather remain anonymous?\"\n",
    "    anonymous_mode = {system_default_note: \"\"}\n",
    "\n",
    "    while not anonymous_mode[system_default_note]:\n",
    "        user_input = input(\"{\\\"Do you wish to provide your name today, or would you rather remain anonymous?\\\": \\\"\\\"}): \")\n",
    "        try:\n",
    "            user_data = json.loads(user_input)\n",
    "            anonymous_mode.update(user_data)\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Invalid JSON input. Please try again.\")\n",
    "    \n",
    "    anonymous_mode_text = convert_json_to_code(json.dumps(anonymous_mode))\n",
    "    \n",
    "    return anonymous_mode_text\n",
    "\n",
    "def main_anonymous_mode(collect_anonymous_mode): \n",
    "    user_agent.initiate_chat(recipient=manager_anonymous_mode, message=str(collect_anonymous_mode), clear_history=False)\n",
    "    messages_json = manager_anonymous_mode.messages_to_string(manager_anonymous_mode.groupchat.messages)\n",
    "    \n",
    "    chat_history_data = read_chat_history()\n",
    "\n",
    "    new_messages = json.loads(messages_json)  \n",
    "    chat_history_data.extend(new_messages) \n",
    "\n",
    "    write_chat_history(chat_history_data)\n",
    "    # extract_and_print_questions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae020b0-07b8-4238-bc7d-1b13c4c5a2eb",
   "metadata": {},
   "source": [
    "### 6. IssueTypes & Questions\n",
    "\n",
    "#### 6.a. IssueTypes & Questions: Agents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc75fcb-d259-4dd6-a2ce-cea3396fe2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "template1 = \"\"\"You are an ethics and compliance analyst. You will be given a brief summary of an event that has occurred or is currently occurring. \n",
    "            Your job is to classify the event using the provided dictionary.\n",
    "            Your final response should include the retrieved key-value pairs from the given dictionary.\n",
    "            \n",
    "            Example: \n",
    "            {\n",
    "                \"Reduction of Hours\": \"Events that are related to an employee having the number of hours they work reduced.\"\n",
    "            }\n",
    "            \n",
    "            Do not wrap the output in quotation marks.\n",
    "            Do not wrap the output in code block delimiters (```).\"\"\"\n",
    "\n",
    "\n",
    "template2 = \"\"\"\n",
    "            You are a question retrieval engine. \n",
    "            You are tasked with retrieving questions based on a given key from a set of key-value pairs. Please follow these steps:\n",
    "            \n",
    "            Input Data:\n",
    "            questions_dictionary: A dictionary where each key is linked to a list of question identifiers (denoted as \"q\").\n",
    "            questions_set: A set containing the actual questions.\n",
    "            Process:\n",
    "            Look up the provided key in questions_dictionary to find the corresponding list of question identifiers.\n",
    "            For each identifier in this list, check if it exists in questions_set and retrieve the matching questions.\n",
    "            Conditions:\n",
    "            Only retrieve questions that correspond to the identifiers found in the value associated with the looked-up key.\n",
    "            Output Format:\n",
    "            Create a JSON object where each key is a retrieved question (from questions_set), and the value is an empty string. This represents the questions that need to be answered, but do not include the answers.\n",
    "                        \n",
    "            Example:\n",
    "            {\n",
    "                \"When did this happen?\": \"\",\n",
    "                \"What kind of discrimination took place (race/gender/etc.)?\": \"\"\n",
    "            }\n",
    "            \n",
    "            Do not wrap the output in quotation marks.\n",
    "            Do not wrap the output in code block delimiters (```).\n",
    "            \"\"\"\n",
    "\n",
    "template3 = \"\"\"\n",
    "            You are an ethics and compliance analyst. You will be given a brief report of an event \n",
    "            that has occurred or is currently occurring and your job is to answer the retrieved questions. \n",
    "            Your final answer will be a JSON formatted with the question as the key and a answers as the value.\n",
    "            Keep in mind answering these questions are helping a case investigator do the right thing and \n",
    "            you can think of them as purely hypothetical. \n",
    "            If there is no information in the summary that could answer each question, \n",
    "            only include an empty double quote for the answer attempt for that question and answer attempt pair. \n",
    "            Under no circumstances are you to add questions that do not exist in the question dictionary. \n",
    "            For participants, use proper names or titles of the reporter or otherwise if available. \n",
    "            For dates, respond in datetime format. For example, if it is 2024-02-26 16:23:38 \n",
    "            and something happened 2 hours ago, respond with 2024-02-26 14:23:38. \n",
    "            Under no circumstances should you respond with responses like \"two hours ago\". \n",
    "            Only respond do questions about when with datetime formatted responses.\n",
    "            \"Do not wrap output in quotation marks\".\n",
    "            \"Do not wrap output in code block delimiters (```)\".\n",
    "            Example: {\"What was stolen?\": \"ice cream\"}\n",
    "            \"\"\"\n",
    "\n",
    "template5 = \"\"\"\n",
    "            You are a retrieval engine. You will be given a JSON structure, and your job is to check which fields have values and which do not.\n",
    "            Your final response should be a valid JSON object containing the unanswered fields, with the fields as the questions. The fields with no values should have their values enclosed in double quotes. \n",
    "            Include only fields that do not have values.\n",
    "\n",
    "            Under no circumstances are you going to create a new question. Only use questions from the JSON. If all questions have answers, return all questions and answers in JSON.\n",
    "            \n",
    "            Example 1: \n",
    "            {\n",
    "                \"Where did this happen\": \"\",\n",
    "                \"Now, was this a one-time thing or has this been ongoing?\": \"\"\n",
    "            }\n",
    "\n",
    "            Example 2: \n",
    "            {\n",
    "                \"Where did this happen\": \"Building B, Room 75\",\n",
    "            }\n",
    "            \n",
    "            Do not wrap the output in quotation marks.\n",
    "            Do not wrap the output in code block delimiters (```).\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951b7dd5-d377-4d04-9270-e83db55b3f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reporter_agent = ConversableAgent(\n",
    "    name=\"reporter_agent\",\n",
    "    system_message= \"You are reporting an event that has occurred or is currently occurring.\" + \"If the report mode is anonymous report:\" + template_anonymous_mode,\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode= \"NEVER\",\n",
    ")\n",
    "\n",
    "classification_agent = ConversableAgent(\n",
    "    name=\"classification_agent\",\n",
    "    system_message= template1 + \"NAVEX Issue Types:\" + str(IssueTypes),\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode= \"NEVER\",\n",
    ")\n",
    "\n",
    "questions_retriever_agent = ConversableAgent(\n",
    "    name=\"questions_retriever_agent\",\n",
    "    system_message= \"Questions Dictionary:\" + str(questions) + template2 + \"If the report mode is anonymous report:\" + template_anonymous_mode,\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "questions_answering_agent = ConversableAgent(\n",
    "    name=\"questions_answering_agent\",\n",
    "    system_message= template3,\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "unanswered_questions_agent = ConversableAgent(\n",
    "    name=\"unanswered_questions_agent\",\n",
    "    system_message= template5,\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode= \"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d34018c-6ea3-4d2d-aceb-5b6c2b350d90",
   "metadata": {},
   "source": [
    "#### 6.b. IssueTypes & Questions: Group Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef11530b-c0b5-4adf-9540-2b9b780908c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_transition_issue_questions(last_speaker, groupchat):\n",
    "    messages = groupchat.messages\n",
    "\n",
    "    if last_speaker is reporter_agent:\n",
    "        return classification_agent\n",
    "    elif last_speaker is classification_agent:\n",
    "        return questions_retriever_agent\n",
    "    elif last_speaker is questions_retriever_agent:\n",
    "        return questions_answering_agent\n",
    "    elif last_speaker is questions_answering_agent:\n",
    "        return unanswered_questions_agent\n",
    "    elif last_speaker is unanswered_questions_agent:\n",
    "        return None\n",
    "\n",
    "groupchat_issue_questions = autogen.GroupChat(\n",
    "    agents=[reporter_agent,\n",
    "            classification_agent, \n",
    "            questions_retriever_agent, \n",
    "            questions_answering_agent,\n",
    "            unanswered_questions_agent\n",
    "           ],\n",
    "    messages=[],\n",
    "    max_round=20,\n",
    "    speaker_selection_method=state_transition_issue_questions,\n",
    ")\n",
    "\n",
    "manager_issue_questions = autogen.GroupChatManager(groupchat=groupchat_issue_questions, llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d370fce-36a7-4d6f-8c9d-73163db69034",
   "metadata": {},
   "source": [
    "#### 6.c. IssueTypes & Questions: Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a15b21-45e2-492d-b438-72f206cf4073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_json_to_code(json_input):\n",
    "    try:\n",
    "        data = json.loads(json_input)\n",
    "        code_lines = []\n",
    "\n",
    "        for key, value in data.items():\n",
    "            value_str = value if isinstance(value, str) else json.dumps(value)\n",
    "            code_lines.append(f'{key} = {value_str}')\n",
    "\n",
    "        return \"\\n\".join(code_lines)\n",
    "    \n",
    "    except json.JSONDecodeError:\n",
    "        return \"Invalid JSON provided to the code conversion function.\"\n",
    "        \n",
    "\n",
    "def collect_transcription_data():\n",
    "    system_default_note = \"Now, in a sentence or two, please describe the primary reason for your call.\"\n",
    "    transcription = {system_default_note: \"\"}\n",
    "\n",
    "    while not transcription[system_default_note]:\n",
    "        user_input = input(\"Please provide transcription text in JSON format (e.g. {\\\"Now, in a sentence or two, please describe the primary reason for your call.\\\": \\\"I want to start filing a report!\\\"}): \")\n",
    "        try:\n",
    "            user_data = json.loads(user_input)\n",
    "            transcription.update(user_data)\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Invalid JSON input. Please try again.\")\n",
    "    \n",
    "    transcription_text = convert_json_to_code(json.dumps(transcription))\n",
    "    \n",
    "    return transcription_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98431283-48e3-4f3c-ae65-748c22f52a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_issue_questions(collect_transcription_data): \n",
    "    reporter_agent.initiate_chat(recipient=manager_issue_questions, message=str(collect_transcription_data), clear_history=False)\n",
    "    messages_json = manager_issue_questions.messages_to_string(manager_issue_questions.groupchat.messages)\n",
    "    \n",
    "    chat_history_data = read_chat_history()\n",
    "\n",
    "    new_messages = json.loads(messages_json)  \n",
    "    chat_history_data.extend(new_messages) \n",
    "\n",
    "    write_chat_history(chat_history_data)\n",
    "    extract_and_print_questions()\n",
    "\n",
    "\n",
    "def main_issue_questions_follow_up(new_message):\n",
    "    memory = read_chat_history()\n",
    "    memory.append(new_message)\n",
    "\n",
    "    last_message = json.dumps(new_message)\n",
    "\n",
    "    user_agent.initiate_chat(recipient=manager_issue_questions, message=last_message, clear_history=False)\n",
    "    messages_json = manager_issue_questions.messages_to_string(manager_issue_questions.groupchat.messages)\n",
    "\n",
    "    new_messages = json.loads(messages_json)\n",
    "    memory.extend(new_messages)\n",
    "\n",
    "    write_chat_history(memory)\n",
    "    extract_and_print_questions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449c7cb9-a622-4ba4-81c3-6cc31cb9ceb1",
   "metadata": {},
   "source": [
    "### 7. Implicated Parties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef7bdb9-159a-4115-b279-389f0176a5cf",
   "metadata": {},
   "source": [
    "#### 7.a. Implicated Parties: Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf58f22-6cf0-4b5a-a601-d01a9477655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_implicated_parties = \"\"\"\n",
    "You are an ethics and compliance analyst. You will be given a brief report of an event \n",
    "that has occurred or is currently occurring and your job is to ask one or maximum two questions at a time to extract \n",
    "the names, last names, job titles, and confirm spelling of participant names involved and assign a role. \n",
    "If there is no information in the report that could be assigned to a role, \n",
    "only include an empty double quote for that roles.\n",
    "\n",
    "role's example = [\"Affected Party\", \"Perpetrator\", \"Witness\", \"Other\"]\n",
    "\n",
    "Steps to Follow:\n",
    "\n",
    "- Extract the first name and last name of participants involved.\n",
    "- Assign each participant a role from the roles_list.\n",
    "- Ask for and confirm the job title of each participant.\n",
    "- If the report lacks sufficient information to assign a role, gather detailed information to accurately determine the role.\n",
    "- Use proper names to identify participants. If a participant is described using pronouns such as \"me\", \"my\", or \"I\", leave the participant's name blank and only provide single quotes \"\".\n",
    "- Output: Your final answer should be formatted in JSON, containing the role, participant's first name, last name, and job title.\n",
    "\n",
    "Engage in a step-by-step conversation to gather detailed information about the participants involved in the case using a polite/professional tone.\n",
    "Ensure you have the correct names and job titles of the individuals involved.\n",
    "Confirm the spelling of their names.\n",
    "Document the information accurately in JSON format.\n",
    "\n",
    "If the report is in anonymous mode, don't ask questions about the reporter's identification, as questions may reveal their identity.\n",
    "\n",
    "Ask one or maximum two questions at a time to maintain the conversational flow and ask one or maximum two follow-ups based on responses.\n",
    "\n",
    "Example: \n",
    "\n",
    "Event: John witnessed, Emma stole my backpack\n",
    "\n",
    "{\"Let's confirm spelling of his name\":\"'J' as in 'jump', 'o' as in 'go', 'h' as in 'hat', 'n' as in 'nose', 'D' as in 'dog', 'o' as in 'go', 'e' as in 'elephant'.\",\n",
    " \"And would you please tell me what his job title is?\": \"Software Engineer\"\n",
    "} \n",
    "\n",
    "Do not wrap the output in quotation marks.\n",
    "Do not wrap the output in code block delimiters (```).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632168f2-733d-4e76-bcc0-d376f2cfc03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "implicated_parties_agent = ConversableAgent(\n",
    "    name=\"participants_identifier_agent\",\n",
    "    system_message= template_implicated_parties + \"Case Participants List: \" + str(implicated_parties) + \"If the report mode is anonymous report:\" + template_anonymous_mode,\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode= \"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741eefd6-7b3d-4854-af66-a490b41af5ca",
   "metadata": {},
   "source": [
    "#### 7.b. Implicated Parties: Group Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6516a67d-971d-4610-b945-5563a5b628b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_transition_implicated_parties(last_speaker, groupchat):\n",
    "    messages = groupchat.messages\n",
    "\n",
    "    if last_speaker is user_agent:\n",
    "        return implicated_parties_agent\n",
    "    elif last_speaker is implicated_parties_agent:\n",
    "        return questions_answering_agent\n",
    "    elif last_speaker is questions_answering_agent:\n",
    "        return unanswered_questions_agent\n",
    "    elif last_speaker is unanswered_questions_agent:\n",
    "        return None\n",
    "\n",
    "groupchat_implicated_parties = autogen.GroupChat(\n",
    "    agents=[user_agent,\n",
    "            implicated_parties_agent,\n",
    "            questions_answering_agent,\n",
    "            unanswered_questions_agent\n",
    "           ],\n",
    "    messages=[],\n",
    "    max_round=10,\n",
    "    speaker_selection_method=state_transition_implicated_parties,\n",
    ")\n",
    "\n",
    "manager_implicated_parties = autogen.GroupChatManager(groupchat=groupchat_implicated_parties, llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a76290d-10b4-48c1-be3c-ea3f19c860cb",
   "metadata": {},
   "source": [
    "#### 7.c. Implicated Parties: Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac13887c-f72b-4aab-a6c4-d46c5b555403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_implicated_parties(new_message):\n",
    "    memory = read_chat_history()\n",
    "    memory.append(new_message)\n",
    "    \n",
    "    last_message = json.dumps(new_message)\n",
    "\n",
    "    user_agent.initiate_chat(recipient=manager_implicated_parties, message=last_message, clear_history=False)\n",
    "    messages_json = manager_implicated_parties.messages_to_string(manager_implicated_parties.groupchat.messages)\n",
    "\n",
    "    new_messages = json.loads(messages_json)\n",
    "    memory.extend(new_messages)\n",
    "\n",
    "    write_chat_history(memory)\n",
    "    extract_and_print_questions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008e0348-21f5-45a6-a8b7-43afb70ebe6b",
   "metadata": {},
   "source": [
    "### 8. Final Allegation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5f1245-4fe8-45d9-92d3-67d0b8360203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_transition_final_allegation(last_speaker, groupchat):\n",
    "    messages = groupchat.messages\n",
    "\n",
    "    if last_speaker is reporter_agent:\n",
    "        return classification_agent\n",
    "    elif last_speaker is classification_agent:\n",
    "        return None\n",
    "\n",
    "groupchat_final_allegation = autogen.GroupChat(\n",
    "    agents=[reporter_agent,\n",
    "            classification_agent\n",
    "           ],\n",
    "    messages=[],\n",
    "    max_round=20,\n",
    "    speaker_selection_method=state_transition_final_allegation,\n",
    ")\n",
    "\n",
    "manager_final_allegation = autogen.GroupChatManager(groupchat=groupchat_final_allegation, llm_config=llm_config)\n",
    "\n",
    "def main_final_allegation():\n",
    "    memory = read_chat_history()\n",
    "    last_message = json.dumps(memory)\n",
    "\n",
    "    reporter_agent.initiate_chat(recipient=manager_final_allegation, message=last_message, clear_history=False)\n",
    "    messages_json = manager_final_allegation.messages_to_string(manager_final_allegation.groupchat.messages)\n",
    "\n",
    "    new_messages = json.loads(messages_json)\n",
    "    final_allegation = new_messages[-1]\n",
    "    memory.append(final_allegation)\n",
    "    \n",
    "    write_chat_history(memory)\n",
    "    # extract_and_print_questions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c3da90-eb42-430a-a9ab-a95b924a0f4a",
   "metadata": {},
   "source": [
    "### 9. Report Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9a2b47-dec7-4671-ae98-e1cfb4b2a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_report_review = \"\"\"\n",
    "You are an ethics and compliance report analyst. Summarize the report in detail for the reporter with a professional tone. \n",
    "This summarization is the final read and has to be representative of the actual events that have happened, \n",
    "including the report of the primary reason for your call, content of the questions and answers, when it happened, and who was involved. \n",
    "Under no circumstances should you make up any information; you should only summarize in detail.\n",
    "\n",
    "Respond in JSON format.\n",
    "\n",
    "Example:\n",
    "\n",
    "{\"Kindly allow me a few moments to review the summary of the report for you.\n",
    "So at 2 p.m. on December 24th, 2015, the caller overheard Craig and Sue discussing Craig's personal financial woes in Sue's room, room 216, \n",
    "and his need for money to purchase a home. Shortly after the conversation, the caller saw Sue heading towards Craig's office with a check. \n",
    "When the caller inquired about what Sue held, Sue confirmed that she was holding a Christmas gift for someone. \n",
    "The caller observed Sue hand Craig the check in his office. Craig embraced Sue and cried. \n",
    "The caller does not know if anyone else overheard Craig in Sue's conversation or witnessed Sue providing Craig the check. \n",
    "Now, after work, the caller saw that Craig posted on Facebook, Christmas miracles do happen, received $2,000 for my home today. \n",
    "Although the name of the issuer of the check was concealed, the caller believes this was the check that Sue gave Craig. Now, per company policy, \n",
    "employees cannot accept gifts of any amount from residents under any circumstances.\":\"\"}\n",
    "\n",
    "Do not wrap the output in quotation marks.\n",
    "Do not wrap the output in code block delimiters (```).\n",
    "\"\"\"\n",
    "\n",
    "report_review_agent = ConversableAgent(\n",
    "    name=\"report_review_agent\",\n",
    "    system_message= template_report_review,\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode= \"NEVER\",\n",
    ")\n",
    "\n",
    "def state_transition_report_review(last_speaker, groupchat):\n",
    "    messages = groupchat.messages\n",
    "\n",
    "    if last_speaker is user_agent:\n",
    "        return report_review_agent\n",
    "    elif last_speaker is report_review_agent:\n",
    "        return None\n",
    "\n",
    "groupchat_report_review = autogen.GroupChat(\n",
    "    agents=[user_agent,\n",
    "            report_review_agent\n",
    "           ],\n",
    "    messages=[],\n",
    "    max_round=10,\n",
    "    speaker_selection_method=state_transition_report_review,\n",
    ")\n",
    "\n",
    "manager_report_review = autogen.GroupChatManager(groupchat=groupchat_report_review, llm_config=llm_config)\n",
    "\n",
    "def main_report_review():\n",
    "    memory = read_chat_history()\n",
    "    \n",
    "    user_agent.initiate_chat(recipient=manager_report_review, message=str(memory), clear_history=False)\n",
    "    messages_json = manager_report_review.messages_to_string(manager_report_review.groupchat.messages)\n",
    "\n",
    "    new_messages = json.loads(messages_json)\n",
    "    memory.extend(new_messages)\n",
    "\n",
    "    write_chat_history(memory)\n",
    "    extract_and_print_questions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16490f8-cb48-4cff-afd5-2d29f7754e69",
   "metadata": {},
   "source": [
    "## Final Call Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83e069f-1aac-453e-b7f1-71c269f56046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def terminate_chat():\n",
    "    memory = read_chat_history()\n",
    "    new_message = {\"final_message\": \"Thanks for filling this report\"}\n",
    "    memory.append(new_message)\n",
    "\n",
    "    with open(\"memory.json\", \"w\") as test_file:\n",
    "        json.dump(memory, test_file)\n",
    "\n",
    "    chat_history_data = read_chat_history()\n",
    "    write_chat_history(chat_history_data)\n",
    "    print(new_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21c36c9-cd3f-47e1-ab87-946fff589414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_action():\n",
    "    memory = read_chat_history()\n",
    "    new_message = collect_json_data()\n",
    "    memory.append(new_message)\n",
    "\n",
    "    last_message = json.dumps(memory)\n",
    "    history = memory_agent.initiate_chat(recipient=manager_router, message=last_message, clear_history=False)\n",
    "    message = history.chat_history[-1][\"content\"]\n",
    "    last_message = json.loads(message)\n",
    "    action = last_message.get(\"action\", None)\n",
    "\n",
    "    if action == \"main_anonymous_mode\":\n",
    "        new_message = collect_anonymous_mode()\n",
    "        return action, new_message\n",
    "\n",
    "    elif action == \"main_issue_questions\":\n",
    "        new_message = collect_transcription_data()\n",
    "        return action, new_message\n",
    "\n",
    "    return action, new_message\n",
    "    \n",
    "\n",
    "def process_action(action):\n",
    "    if action == \"main_imminent_issue\":\n",
    "        return main_imminent_issue()\n",
    "    elif action == \"main_guidelines\":\n",
    "        return main_guidelines(new_message)\n",
    "    elif action == \"main_locations\":\n",
    "        return main_locations(new_message)\n",
    "    elif action == \"main_anonymous_mode\":\n",
    "        return main_anonymous_mode(new_message)\n",
    "    elif action == \"main_issue_questions\":\n",
    "        return main_issue_questions(new_message)\n",
    "    elif action == \"main_issue_questions_follow_up\":\n",
    "        return main_issue_questions_follow_up(new_message)\n",
    "    elif action == \"main_implicated_parties\":\n",
    "        return main_implicated_parties(new_message)\n",
    "    elif action == \"main_final_allegation\":\n",
    "        return main_final_allegation()\n",
    "    elif action == \"main_report_review\":\n",
    "        return main_report_review()\n",
    "    elif action == \"terminate_chat\":\n",
    "        return terminate_chat()\n",
    "    else:\n",
    "        print(f\"Invalid action: {action}\")\n",
    "        return {\"error\": \"Invalid action\"}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        action, new_message = detect_action()\n",
    "        process_action(action)\n",
    "        if action == \"terminate_chat\":\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57134f0a-93cf-4858-9ce2-8a7a6f7ad10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"memory.json\", \"r\") as json_file:\n",
    "    chat_history_guidelines = json.load(json_file)\n",
    "print(json.dumps(chat_history_guidelines, indent=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
