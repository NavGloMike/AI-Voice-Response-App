{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ba49f59-e8f5-49f1-abb0-8b8ab8117165",
   "metadata": {},
   "source": [
    "## AI-powered Contact Center Intake (AICCI) Agents - Guidelines Design\n",
    "\n",
    " * Created:   Feb 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa1ec7c8-3c97-4edb-ac62-78b4971cd03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "flaml.automl is not available. Please install flaml[automl] to enable AutoML functionalities.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import openai\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "from openai import AzureOpenAI\n",
    "import psycopg\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import autogen\n",
    "from autogen import GroupChat\n",
    "from autogen import GroupChatManager\n",
    "from autogen import AssistantAgent\n",
    "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
    "from autogen import ConversableAgent, UserProxyAgent, config_list_from_json\n",
    "from autogen.retrieve_utils import TEXT_FORMATS\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "from pgvector.psycopg2 import register_vector\n",
    "from autogen import AssistantAgent, ConversableAgent, UserProxyAgent\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "438f7a80-f860-4fad-b064-e29c5a05b4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "    \"config_list\": [\n",
    "        {\n",
    "            \"model\": \"gpt-4o\",\n",
    "            \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "            \"api_type\": \"azure\",\n",
    "            \"base_url\": os.getenv(\"OPENAI_API_BASE\"),\n",
    "            \"api_version\": os.getenv(\"API_VERSION\"),\n",
    "        },\n",
    "    ],\n",
    "    \"temperature\": 0.0,\n",
    "    \"timeout\": 300,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88149d65-2a9a-40df-8a2a-cbdcd6ac392a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  \n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "azure_endpoint = os.getenv(\"OPENAI_API_BASE\")\n",
    "api_version = os.getenv(\"API_VERSION\")\n",
    "model = \"gpt-4o\"\n",
    "temprature = 0.0\n",
    "top_p = 1.0\n",
    "\n",
    "def get_response_client(template, text, temprature=temprature, top_p=top_p, model=model, azure_endpoint=azure_endpoint, api_key=api_key, api_version=api_version):\n",
    "    time.sleep(1)\n",
    "\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint = azure_endpoint, \n",
    "        api_key= api_key,  \n",
    "        api_version= api_version\n",
    "    )\n",
    "\n",
    "    conversation = [\n",
    "        {\"role\": \"system\", \"content\": template},\n",
    "        {\"role\": \"user\", \"content\": text},\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=temprature,\n",
    "        top_p= top_p,\n",
    "        max_tokens=4000,\n",
    "        response_format={ \"type\": \"json_object\" },  #JSON mode\n",
    "        messages=conversation\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d76520d5-8e37-4ef2-9e30-2c836031cebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #print(os.getcwd())\n",
    "# file_path = \"/Users/kylezarif/Documents/Github/datascience/Agentic_AI/AutoGen/autogen/HighVolClients.csv\"\n",
    "# df = pd.read_csv(file_path)\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db2bd55b-a3db-40ac-9321-fcfc72f7aa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_base = df.groupby('ClientName').agg({\n",
    "#     'Guidelines': lambda x: ' '.join(x),\n",
    "#     'CustomFile': 'first'\n",
    "# }).reset_index()\n",
    "\n",
    "# print(df_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd673785-3709-4e6b-8ed1-79cc33d9c2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_colwidth', None)  # Set to None to display all text in a column\n",
    "\n",
    "# test = df_base[df_base['ClientName'] == 'Amazon']\n",
    "# display(test['Guidelines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5aafd596-9c00-465e-bb0b-423877ae5474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option1: BeautifulSoup 'html.parser'\n",
    "# Option2: Gen AI tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f332f7ea-33fc-4b08-885f-bea93eccdb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_dirty = \"\"\"\n",
    "<html> <head> <title>Amazon Corporate</title> <!-- <link rel=\"stylesheet\" type=\"text/css\" href=\"ciCC.css\" /> --> <script type=\"text/javascript\"> function showhide(num){ var rows = 1; // Number of rows to show/hide //; for(i=1; i<=rows; i++){ which = document.getElementById('row'+i); if(num == i){ which.style.display = (which.style.display=='block') ? 'none':'block'; } else{which.style.display = 'none'}; } } </script>  <script type=\"text/javascript\">     function expander(id) {         if (document.getElementById(id).style.display === \"none\") {             document.getElementById(id).style.display = \"block\";             // Custom containers             if ((id === \"CustomSHOWYES1\") && (document.getElementById(\"CustomSHOWNO1\").style.display === \"block\")) {                 document.getElementById(\"CustomSHOWNO1\").style.display = \"none\";             }             if ((id === \"CustomSHOWNO1\") && (document.getElementById(\"CustomSHOWYES1\").style.display === \"block\")) {                 document.getElementById(\"CustomSHOWYES1\").style.display = \"none\";             }             if ((id === \"CustomSHOWYES2\") && (document.getElementById(\"CustomSHOWNO2\").style.display === \"block\")) {                 document.getElementById(\"CustomSHOWNO2\").style.display = \"none\";             }             if ((id === \"CustomSHOWNO2\") && (document.getElementById(\"CustomSHOWYES2\").style.display === \"block\")) {                 document.getElementById(\"CustomSHOWYES2\").style.display = \"none\";             }          } else {             document.getElementById(id).style.display = \"none\";         }     } </script> <style>     ul {         margin: 10px 0;     } </style> </head> <body> <ul style=\"list-style:disc\">     <!-- FIRST YES OR NO -->     <li><span id=\"firstYES\" style=\"color:#0000f1;font-weight:bold;text-decoration:underline;cursor: pointer;\" onclick=\"expander('firstSHOW'); expander('firstSHOWYES');\">YES</span> / <span id=\"firstNO\" style=\"color:red;font-weight:bold;text-decoration:underline;cursor: pointer;\" onclick=\"expander('firstSHOW'); expander('firstSHOWNO');\">NO</span></li>     <ul id=\"firstSHOW\" style=\"list-style:disc; display: none;\">         <!-- CUSTOM NEW STUFF -->             <li style=\"display: none;\" id=\"firstSHOWYES\">Do you work (or did you work) for a DSP Company (or Business) that delivers packages for Amazon? (DSP driver) <span style=\"color:#0000f1;font-weight:bold;text-decoration:underline;cursor: pointer;\" onclick=\"expander('CustomSHOWYES1')\">YES</span> / <span style=\"color:red;font-weight:bold;text-decoration:underline;cursor: pointer;\" onclick=\"expander('CustomSHOWNO1')\">NO</span></li>             <li style=\"display: none;\" id=\"firstSHOWNO\">Do you deliver packages on road for Amazon either through the DSP, FLEX, HUB Program and Walker Program? <span style=\"color:#0000f1;font-weight:bold;text-decoration:underline;cursor: pointer;\" onclick=\"expander('CustomSHOWYES1')\">YES</span> / <span style=\"color:red;font-weight:bold;text-decoration:underline;cursor: pointer;\" onclick=\"expander('CustomSHOWNO1')\">NO</span></li>             <ul id=\"CustomSHOWYES1\" style=\"list-style:disc; display: none;\">                 <li style=\"color:#006600;\"><span style=\"background:#006600;color:white;font-weight:bold;\">READ:</span> Before we begin, please know that you will need to remain on the line until we've completed the entire interview process to ensure Amazon is able to address your concern as warranted. At the end of this process, I will provide you with a report key so you may follow up on this report. Do you wish to proceed?</li>                 <li>Click <a href=\"https://secure.ethicspoint.com/domain/en/callcenter_report_custom.asp?clientid=65221\" rel=\"newwindow\" target=\"_blank\">here</a> to file a report under the <strong>Last Mile Drivers</strong> program.</li>             </ul>             <ul id=\"CustomSHOWNO1\" style=\"list-style:disc; display: none;\">                 <li>Do you or have you ever delivered packages for Amazon? <span style=\"color:#0000f1;font-weight:bold;text-decoration:underline;cursor: pointer;\" onclick=\"expander('CustomSHOWYES2')\">YES</span> / <span style=\"color:red;font-weight:bold;text-decoration:underline;cursor: pointer;\" onclick=\"expander('CustomSHOWNO2')\">NO</span></li>             </ul>             <ul id=\"CustomSHOWYES2\" style=\"list-style:disc; display: none;\">                 <li style=\"color:#006600;\"><span style=\"background:#006600;color:white;font-weight:bold;\">READ:</span> Before we begin, please know that you will need to remain on the line until we've completed the entire interview process to ensure Amazon is able to address your concern as warranted. At the end of this process, I will provide you with a report key so you may follow up on this report. Do you wish to proceed?</li>                 <li>Click <a href=\"https://secure.ethicspoint.com/domain/en/callcenter_report_custom.asp?clientid=65221\" rel=\"newwindow\" target=\"_blank\">here</a> to file a report under the <strong>Last Mile Drivers</strong> program.</li>             </ul>             <ul id=\"CustomSHOWNO2\" style=\"list-style:disc; display: none;\">                 <li style=\"color:#006600;\"><span style=\"background:#006600;color:white;font-weight:bold;\">READ:</span> Before we begin, please know that you will need to remain on the line until we've completed the entire interview process to ensure Amazon is able to address your concern as warranted. At the end of this process, I will provide you with a report key so you may follow up on this report. Do you wish to proceed?</li>                 <br>                 <li><span style=\"background:red;color:white;font-weight:bold;\">DON'T READ:</span> If the caller has reached the correct line, click <a href=\"https://secure.ethicspoint.com/domain/en/callcenter_report_custom.asp?clientid=44171\" rel=\"newwindow\" target=\"_blank\">here</a> to file a new report.</li>             </ul>         <br>     </ul> </ul> <p><span style=\"background:red;color:white;font-weight:bold;\">NOTE:</span> Amazon accepts reports from drivers who deliver Amazon packages.  Proceed with those calls.</p> </body> </html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67858c1f-032d-4098-b364-a716a45ce47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Questions': [{'question': 'Do you work (or did you work) for a DSP Company (or Business) that delivers packages for Amazon? (DSP driver)', 'options': ['YES', 'NO']}, {'question': 'Do you deliver packages on road for Amazon either through the DSP, FLEX, HUB Program and Walker Program?', 'options': ['YES', 'NO']}, {'question': 'Do you or have you ever delivered packages for Amazon?', 'options': ['YES', 'NO']}], 'READ': [\"Before we begin, please know that you will need to remain on the line until we've completed the entire interview process to ensure Amazon is able to address your concern as warranted. At the end of this process, I will provide you with a report key so you may follow up on this report. Do you wish to proceed?\"], 'DONT READ': ['If the caller has reached the correct line, click here to file a new report.'], 'Important Notes': ['Amazon accepts reports from drivers who deliver Amazon packages. Proceed with those calls.'], 'Redirects': ['Click here to file a report under the Last Mile Drivers program.']}\n"
     ]
    }
   ],
   "source": [
    "template_eda_guidelines = \"\"\"\n",
    "Role: Assistant to extract text from HTML to JSON.\n",
    "Objective: Extract text in JSON from text or HTML elements to a valid JSON.\n",
    "Make sure the YES / NO is printed after the assocaited question.\n",
    "Extract text in JSON from text or HTML elements similar to the following format in a valid JSON. \n",
    "\n",
    "{ \"DONT READ\": \"Instructions or notes meant for the AI agent or customer service representative that should not be read aloud to the caller.\", \"READ\": \"Scripted statements or questions that should be read aloud to the caller.\", \"Instructions\": \"General guidelines or procedures that the AI agent or customer service representative should follow during the call.\", \"Follow-Up Report Instructions\": \"Specific steps to follow when handling follow-up reports, including what to say to the caller and how to process the report.\", \"Frequently Asked Questions (FAQ)\": \"Common questions and answers related to reporting, company policies, and procedures.\", \"Redirects\": \"Information on who to contact or where to direct the caller for specific requests or issues that are outside the scope of the current call.\", \"Partial Reports Instructions\": \"Guidelines for handling and submitting partial reports, including any special procedures or passwords required.\", \"Company List\": \"A list of companies or subsidiaries that are relevant to the reporting process.\", \"Important Notes\": \"Critical information that needs special attention, such as changes in service providers or specific instructions for certain types of reports.\", \"Customer Service Notes (CS NOTES)\": \"Additional instructions or notes for customer service representatives to follow during the call.\", \"Questions\": \"Custom questions that the AI agent should ask the caller to gather necessary information for the report.\", \"Clarification about reports to file or not file\": \"Guidance on whether a report should be filed based on the caller's information or situation.\", \"Location selection\": \"Instructions or options for selecting the relevant location for the report.\", \"Case questions\": \"Specific questions related to the details of the case being reported.\", \"Involved parties\": \"Information or questions about the individuals or entities involved in the report.\", \"Closing\": \"Instructions or statements for concluding the call or report.\", \"Closing messages\": \"Scripted messages to be read at the end of the call.\", \"Report follow-up info\": \"Information provided to the caller about how they can follow up on their report.\" } \n",
    "\n",
    "Do not wrap the output in quotation marks.\n",
    "Do not wrap the output in code block delimiters (```).\n",
    "\"\"\"\n",
    "\n",
    "guidelines = get_response_client(template_eda_guidelines, str(html_dirty))\n",
    "guidelines = json.loads(guidelines)\n",
    "print(guidelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01e9e984-d2d2-4b90-8bcf-be4857e97abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"guidelines.json\", \"w\") as json_file:\n",
    "#     json.dump(guidelines, json_file)\n",
    "\n",
    "# def load_data():\n",
    "#     with open(\"guidelines.json\", \"r\") as json_file:\n",
    "#         data = json.load(json_file)\n",
    "#     return data\n",
    "\n",
    "# guidelines = load_data()\n",
    "# print(\"Guidelines:\", guidelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18bbd67f-2e29-4ce8-93ee-63a522caa46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_memory = \"\"\"\n",
    "Role: You are the JSON Chat Memory Agent.\n",
    "Objective: Your primary responsibility is to memorize the new message and the {{JSON Chat Memory}}.\n",
    "You will take to action!\n",
    "\n",
    "Do not wrap the output in quotation marks.\n",
    "Do not wrap the output in code block delimiters (```).\n",
    "\"\"\"\n",
    "\n",
    "template_router = \"\"\"\n",
    "Role: You are a classification agent responsible for managing the routing of new messages based on predefined rules and priorities.\n",
    "Objective: You will analyze the incoming message, evaluate the associated {{JSON Chat Memory}}, consider the relevant {{group_chat}} priorities, \n",
    "and apply the applicable {{termination_requirements}}. Your task is to:\n",
    "Detect the correct action ID: Based on the new message, refer to the {{JSON Chat Memory}} to determine the appropriate action ID that aligns with the {{termination_requirements}}.\n",
    "Route the message to the appropriate group: After determining the action id, select the next appropriate {{group_chat}} for the message from the available options.\n",
    "\n",
    "{\n",
    "  \"group_chat\": \n",
    "  [\n",
    "   \n",
    "    {\"id\": \"main_guidelines\",\n",
    "    \"priority\": 2, \n",
    "    \"role\": \"This function is used when the JSON Chat Memory does not contain the customer's responses to the READ messages in guidelines/instructions.\",\n",
    "    \"termination_requirements\": {\n",
    "        \"requirement_1\": \"Have answers to all READ messages.\",\n",
    "        \"requirement_2\": \"Have followed instructions for NOT READ messages\",\n",
    "        \"requirement_3\": \"Have identified the caller's intent to determine whether it is a new report or a follow-up.\",\n",
    "        \"requirement_4\": \"Take action by using procedures. Complete the procedures in the instructions, whether it is a new report or a follow-up.\"\n",
    "      }\n",
    "    }\n",
    "    \n",
    "  ]\n",
    "}\n",
    "\n",
    "\n",
    "example: \n",
    "\n",
    "{\"action\":\"main_guidelines\"}\n",
    "\n",
    "Do not wrap the output in quotation marks.\n",
    "Do not wrap the output in code block delimiters (```).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b6c9f6b-0a62-4de1-861f-1cd7232f3319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial chat history: [{}]\n"
     ]
    }
   ],
   "source": [
    "with open(\"memory.json\", \"w\") as json_file:\n",
    "    json.dump([{}], json_file)\n",
    "\n",
    "def load_chat_history():\n",
    "    with open(\"memory.json\", \"r\") as json_file:\n",
    "        chat_history_data = json.load(json_file)\n",
    "    return chat_history_data\n",
    "\n",
    "chat_history = load_chat_history()\n",
    "print(\"Initial chat history:\", chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d98e4c6-d9d2-4dec-a236-642fa3d31063",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_agent = ConversableAgent(\n",
    "    name=\"memory_agent\",\n",
    "    system_message= f\"{template_memory} + chat history: {chat_history}\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode= \"NEVER\",\n",
    ")\n",
    "\n",
    "router_agent = ConversableAgent(\n",
    "    name=\"router_agent\",\n",
    "    system_message= f\"{template_router} + guidelines instructions: {guidelines}\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode= \"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "561a6ed5-b4a2-4bfa-b202-280f64250d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_transition_router(last_speaker, groupchat):\n",
    "    messages = groupchat.messages\n",
    "\n",
    "    if last_speaker is memory_agent:\n",
    "        return router_agent\n",
    "    elif last_speaker is router_agent:\n",
    "        return None\n",
    "\n",
    "groupchat_router = autogen.GroupChat(\n",
    "    agents=[memory_agent,\n",
    "            router_agent\n",
    "           ],\n",
    "    messages=[],\n",
    "    max_round=10,\n",
    "    speaker_selection_method=state_transition_router,\n",
    ")\n",
    "\n",
    "manager_router = autogen.GroupChatManager(groupchat=groupchat_router, llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5d6bb53-9b2e-4c58-ace5-fc073520d61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_guidelines = \"\"\"\n",
    "Role: Ethics and Compliance Contact Center Analyst\n",
    "Objective: Handle calls by following a structured process using provided guidelines and previous chat history.\n",
    "\n",
    "Steps:\n",
    "\n",
    "Start with the \"OPENING\" statement from the guidelines if available.\n",
    "if not:\n",
    "\n",
    "OPENING = 'Thanks you for calling contact center. This is AICCI.'\n",
    "\n",
    "Sequentially address each \"READ\" message: \n",
    "a. If not addressed, respond with the \"READ\" message. \n",
    "b. If addressed, move to the next \"READ\" message.\n",
    "Determine if the call is a \"Follow-Up\" or \"New Report\": \n",
    "a. For \"Follow-Up\", follow \"Other_Instructions\" if available and respond with the \"READ\" message is \"affiliation\"  \n",
    "b. For \"New Report\", follow \"Other_Instructions\" if available.\n",
    "Continue addressing each \"READ\" message in sequence.\n",
    "\n",
    "Example 1: New Report\n",
    "\n",
    "\"OPENING\": \"Text from opening HTML element\"\n",
    "\"READ_1\": \"1st Text to read\"\n",
    "\"READ_2\": \"2nd Text to read\"\n",
    "\n",
    "Do not wrap the output in quotation marks.\n",
    "Do not wrap the output in code block delimiters (```).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b7d7fa5-f816-4268-9dc1-4e2e7325d749",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = ConversableAgent(\n",
    "    name=\"user_agent\",\n",
    "    system_message= f\"You are an assistant\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode= \"NEVER\",\n",
    ")\n",
    "\n",
    "guidelines_agent = ConversableAgent(\n",
    "    name=\"guidelines_agent\",\n",
    "    system_message= f\"guidelines: {guidelines} + {template_guidelines}\",\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode= \"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de31d145-53d5-4158-95db-83ae262c27aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_transition_guidelines(last_speaker, groupchat):\n",
    "    messages = groupchat.messages\n",
    "\n",
    "    if last_speaker is user_agent:\n",
    "        return guidelines_agent\n",
    "    elif last_speaker is guidelines_agent:\n",
    "        return None\n",
    "\n",
    "groupchat_guidelines = autogen.GroupChat(\n",
    "    agents=[user_agent,\n",
    "            guidelines_agent\n",
    "           ],\n",
    "    messages=[],\n",
    "    max_round=10,\n",
    "    speaker_selection_method=state_transition_guidelines,\n",
    ")\n",
    "\n",
    "manager_guidelines = autogen.GroupChatManager(groupchat=groupchat_guidelines, llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ddaae26-eab0-4a3d-adb8-10a818e159cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_json_data():\n",
    "    follow_ups = {\"questions\": []}\n",
    "    while not follow_ups[\"questions\"]:\n",
    "        user_input = input('Please provide data in JSON format (e.g. {\"questions\": [{\"question\": \"your question\", \"answer\": \"your answer\"}]}): ')\n",
    "        try:\n",
    "            user_data = json.loads(user_input)\n",
    "            if isinstance(user_data, dict) and \"questions\" in user_data and isinstance(user_data[\"questions\"], list):\n",
    "                valid = all(isinstance(item, dict) and \"question\" in item and \"answer\" in item for item in user_data[\"questions\"])\n",
    "                if valid:\n",
    "                    follow_ups.update(user_data)\n",
    "                else:\n",
    "                    print(\"Each item in the questions list must be an object with question and answer keys. Please try again.\")\n",
    "            else:\n",
    "                print(\"The JSON input must be an object with a questions key containing a list of question-answer objects. Please try again.\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Invalid JSON input. Please try again.\")\n",
    "    return follow_ups\n",
    "\n",
    "\n",
    "def extract_questions_from_memory(memory):\n",
    "    last_message = memory[-1]\n",
    "    content = last_message[\"content\"]\n",
    "    try:\n",
    "        content_dict = json.loads(content)\n",
    "        if \"questions\" in content_dict and isinstance(content_dict[\"questions\"], list):\n",
    "            return content_dict\n",
    "        else:\n",
    "            raise json.JSONDecodeError(\"Invalid format\", content, 0)\n",
    "    except json.JSONDecodeError:\n",
    "        questions = [q.strip() + \"?\" if not q.strip().endswith(\"?\") else q.strip() for q in content.split(\"\\n\") if q.strip()]\n",
    "        questions_dict = {\"questions\": [{\"question\": q, \"answer\": \"\"} for q in questions]}\n",
    "        return json.dumps(questions_dict)\n",
    "\n",
    "\n",
    "def read_chat_history():\n",
    "    try:\n",
    "        with open(\"memory.json\", \"r\") as json_file:\n",
    "            try:\n",
    "                return json.load(json_file)\n",
    "            except json.JSONDecodeError:\n",
    "                return []  \n",
    "    except FileNotFoundError:\n",
    "        return [] \n",
    "\n",
    "\n",
    "def extract_and_print_questions():\n",
    "    memory = read_chat_history()\n",
    "    questions = extract_questions_from_memory(memory)\n",
    "    print(questions)\n",
    "\n",
    "\n",
    "def write_chat_history(chat_history_data):\n",
    "    seen = set()\n",
    "    unique_messages = []\n",
    "\n",
    "    for message in chat_history_data:\n",
    "        message_str = json.dumps(message, sort_keys=True, ensure_ascii=False)  \n",
    "        if message_str not in seen:\n",
    "            seen.add(message_str)\n",
    "            unique_messages.append(message)\n",
    "\n",
    "    with open(\"memory.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(unique_messages, json_file, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "406f16b1-f1c5-45c1-ad02-c3d86020c835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_guidelines(new_message):\n",
    "    memory = read_chat_history()\n",
    "    memory.append(new_message)\n",
    "\n",
    "    last_message = json.dumps(new_message)\n",
    "\n",
    "    user_agent.initiate_chat(recipient=manager_guidelines, message=last_message, clear_history=False)\n",
    "    messages_json = manager_guidelines.messages_to_string(manager_guidelines.groupchat.messages)\n",
    "\n",
    "    new_messages = json.loads(messages_json)\n",
    "    memory.extend(new_messages)\n",
    "\n",
    "    write_chat_history(memory)\n",
    "    extract_and_print_questions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64c27f40-c7d1-4f74-b0f4-fc682bddf826",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_report_type_checker= \"\"\"\n",
    "Role: classsification agent to determine the call reason.\n",
    "Objective: determine the call reason, whether it is a \"Follow-Up\" or a \"New Report\" in a valid JSON.\n",
    "\n",
    "Example1:\n",
    "{\"report_type\":\"New Report\"}\n",
    "\n",
    "Example2:\n",
    "{\"report_type\":\"Follow-Up\"}\n",
    "\n",
    "Do not wrap the output in quotation marks.\n",
    "Do not wrap the output in code block delimiters (```).\n",
    "\"\"\"\n",
    "\n",
    "report_type_checker_agent = ConversableAgent(\n",
    "    name=\"report_type_checker_agent\",\n",
    "    system_message= template_report_type_checker,\n",
    "    llm_config=llm_config,\n",
    "    human_input_mode= \"NEVER\",\n",
    ")\n",
    "\n",
    "def state_transition_report_type_checker(last_speaker, groupchat):\n",
    "    messages = groupchat.messages\n",
    "\n",
    "    if last_speaker is user_agent:\n",
    "        return report_type_checker_agent\n",
    "    elif last_speaker is report_type_checker_agent:\n",
    "        return None\n",
    "\n",
    "groupchat_report_type_checker = autogen.GroupChat(\n",
    "    agents=[user_agent,\n",
    "            report_type_checker_agent\n",
    "           ],\n",
    "    messages=[],\n",
    "    max_round=10,\n",
    "    speaker_selection_method=state_transition_report_type_checker,\n",
    ")\n",
    "\n",
    "manager_report_type_checker = autogen.GroupChatManager(groupchat=groupchat_report_type_checker, llm_config=llm_config)\n",
    "\n",
    "def main_report_type_checker():\n",
    "    memory = read_chat_history()\n",
    "    last_message = json.dumps(memory)\n",
    "\n",
    "    user_agent.initiate_chat(recipient=manager_report_type_checker, message=last_message, clear_history=False)\n",
    "    messages_json = manager_report_type_checker.messages_to_string(manager_report_type_checker.groupchat.messages)\n",
    "\n",
    "    new_messages = json.loads(messages_json)\n",
    "    report_type_checker = new_messages[-1]\n",
    "    memory.append(report_type_checker)\n",
    "    \n",
    "    write_chat_history(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21c36c9-cd3f-47e1-ab87-946fff589414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please provide data in JSON format (e.g. {\"questions\": [{\"question\": \"your question\", \"answer\": \"your answer\"}]}):  {\"questions\": [{\"question\": \"your question\", \"answer\": \"your answer\"}]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mmemory_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "[{}, {\"questions\": [{\"question\": \"your question\", \"answer\": \"your answer\"}]}]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: router_agent\n",
      "\u001b[0m\n",
      "\u001b[33mrouter_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "{\"action\":\"main_guidelines\"}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "{\"questions\": [{\"question\": \"your question\", \"answer\": \"your answer\"}]}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: guidelines_agent\n",
      "\u001b[0m\n",
      "\u001b[33mguidelines_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "Thank you for calling the contact center. This is AICCI.\n",
      "\n",
      "Before we begin, please know that you will need to remain on the line until we've completed the entire interview process to ensure Amazon is able to address your concern as warranted. At the end of this process, I will provide you with a report key so you may follow up on this report. Do you wish to proceed?\n",
      "\n",
      "Do you work (or did you work) for a DSP Company (or Business) that delivers packages for Amazon? (DSP driver)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "{\"questions\": [{\"question\": \"Thank you for calling the contact center. This is AICCI.?\", \"answer\": \"\"}, {\"question\": \"Before we begin, please know that you will need to remain on the line until we've completed the entire interview process to ensure Amazon is able to address your concern as warranted. At the end of this process, I will provide you with a report key so you may follow up on this report. Do you wish to proceed?\", \"answer\": \"\"}, {\"question\": \"Do you work (or did you work) for a DSP Company (or Business) that delivers packages for Amazon? (DSP driver)?\", \"answer\": \"\"}]}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please provide data in JSON format (e.g. {\"questions\": [{\"question\": \"your question\", \"answer\": \"your answer\"}]}):  {\"questions\": [{\"question\": \"Thank you for calling the contact center. This is AICCI.?\", \"answer\": \"\"}, {\"question\": \"Before we begin, please know that you will need to remain on the line until we've completed the entire interview process to ensure Amazon is able to address your concern as warranted. At the end of this process, I will provide you with a report key so you may follow up on this report. Do you wish to proceed?\", \"answer\": \"Yes please\"}, {\"question\": \"Do you work (or did you work) for a DSP Company (or Business) that delivers packages for Amazon? (DSP driver)?\", \"answer\": \"Yes\"}]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mmemory_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "[{}, {\"questions\": [{\"question\": \"your question\", \"answer\": \"your answer\"}]}, {\"content\": \"{\\\"questions\\\": [{\\\"question\\\": \\\"your question\\\", \\\"answer\\\": \\\"your answer\\\"}]}\", \"role\": \"user\", \"name\": \"user_agent\"}, {\"content\": \"Thank you for calling the contact center. This is AICCI.\\n\\nBefore we begin, please know that you will need to remain on the line until we've completed the entire interview process to ensure Amazon is able to address your concern as warranted. At the end of this process, I will provide you with a report key so you may follow up on this report. Do you wish to proceed?\\n\\nDo you work (or did you work) for a DSP Company (or Business) that delivers packages for Amazon? (DSP driver)\", \"role\": \"user\", \"name\": \"guidelines_agent\"}, {\"questions\": [{\"question\": \"Thank you for calling the contact center. This is AICCI.?\", \"answer\": \"\"}, {\"question\": \"Before we begin, please know that you will need to remain on the line until we've completed the entire interview process to ensure Amazon is able to address your concern as warranted. At the end of this process, I will provide you with a report key so you may follow up on this report. Do you wish to proceed?\", \"answer\": \"Yes please\"}, {\"question\": \"Do you work (or did you work) for a DSP Company (or Business) that delivers packages for Amazon? (DSP driver)?\", \"answer\": \"Yes\"}]}]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: router_agent\n",
      "\u001b[0m\n",
      "\u001b[33mrouter_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "{\"action\":\"main_guidelines\"}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "{\"questions\": [{\"question\": \"Thank you for calling the contact center. This is AICCI.?\", \"answer\": \"\"}, {\"question\": \"Before we begin, please know that you will need to remain on the line until we've completed the entire interview process to ensure Amazon is able to address your concern as warranted. At the end of this process, I will provide you with a report key so you may follow up on this report. Do you wish to proceed?\", \"answer\": \"Yes please\"}, {\"question\": \"Do you work (or did you work) for a DSP Company (or Business) that delivers packages for Amazon? (DSP driver)?\", \"answer\": \"Yes\"}]}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: guidelines_agent\n",
      "\u001b[0m\n",
      "\u001b[33mguidelines_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "Do you deliver packages on road for Amazon either through the DSP, FLEX, HUB Program and Walker Program?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "{\"questions\": [{\"question\": \"Do you deliver packages on road for Amazon either through the DSP, FLEX, HUB Program and Walker Program?\", \"answer\": \"\"}]}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please provide data in JSON format (e.g. {\"questions\": [{\"question\": \"your question\", \"answer\": \"your answer\"}]}):  {\"questions\": [{\"question\": \"Do you deliver packages on road for Amazon either through the DSP, FLEX, HUB Program and Walker Program?\", \"answer\": \"No\"}]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mmemory_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "[{}, {\"questions\": [{\"question\": \"your question\", \"answer\": \"your answer\"}]}, {\"content\": \"{\\\"questions\\\": [{\\\"question\\\": \\\"your question\\\", \\\"answer\\\": \\\"your answer\\\"}]}\", \"role\": \"user\", \"name\": \"user_agent\"}, {\"content\": \"Thank you for calling the contact center. This is AICCI.\\n\\nBefore we begin, please know that you will need to remain on the line until we've completed the entire interview process to ensure Amazon is able to address your concern as warranted. At the end of this process, I will provide you with a report key so you may follow up on this report. Do you wish to proceed?\\n\\nDo you work (or did you work) for a DSP Company (or Business) that delivers packages for Amazon? (DSP driver)\", \"role\": \"user\", \"name\": \"guidelines_agent\"}, {\"questions\": [{\"question\": \"Thank you for calling the contact center. This is AICCI.?\", \"answer\": \"\"}, {\"question\": \"Before we begin, please know that you will need to remain on the line until we've completed the entire interview process to ensure Amazon is able to address your concern as warranted. At the end of this process, I will provide you with a report key so you may follow up on this report. Do you wish to proceed?\", \"answer\": \"Yes please\"}, {\"question\": \"Do you work (or did you work) for a DSP Company (or Business) that delivers packages for Amazon? (DSP driver)?\", \"answer\": \"Yes\"}]}, {\"content\": \"{\\\"questions\\\": [{\\\"question\\\": \\\"Thank you for calling the contact center. This is AICCI.?\\\", \\\"answer\\\": \\\"\\\"}, {\\\"question\\\": \\\"Before we begin, please know that you will need to remain on the line until we've completed the entire interview process to ensure Amazon is able to address your concern as warranted. At the end of this process, I will provide you with a report key so you may follow up on this report. Do you wish to proceed?\\\", \\\"answer\\\": \\\"Yes please\\\"}, {\\\"question\\\": \\\"Do you work (or did you work) for a DSP Company (or Business) that delivers packages for Amazon? (DSP driver)?\\\", \\\"answer\\\": \\\"Yes\\\"}]}\", \"role\": \"user\", \"name\": \"user_agent\"}, {\"content\": \"Do you deliver packages on road for Amazon either through the DSP, FLEX, HUB Program and Walker Program?\", \"role\": \"user\", \"name\": \"guidelines_agent\"}, {\"questions\": [{\"question\": \"Do you deliver packages on road for Amazon either through the DSP, FLEX, HUB Program and Walker Program?\", \"answer\": \"No\"}]}]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: router_agent\n",
      "\u001b[0m\n",
      "\u001b[33mrouter_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "{\"action\":\"main_guidelines\"}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "{\"questions\": [{\"question\": \"Do you deliver packages on road for Amazon either through the DSP, FLEX, HUB Program and Walker Program?\", \"answer\": \"No\"}]}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: guidelines_agent\n",
      "\u001b[0m\n",
      "\u001b[33mguidelines_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "Do you or have you ever delivered packages for Amazon?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "{\"questions\": [{\"question\": \"Do you or have you ever delivered packages for Amazon?\", \"answer\": \"\"}]}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please provide data in JSON format (e.g. {\"questions\": [{\"question\": \"your question\", \"answer\": \"your answer\"}]}):  {\"questions\": [{\"question\": \"Do you or have you ever delivered packages for Amazon?\", \"answer\": \"No\"}]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mmemory_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "[{}, {\"questions\": [{\"question\": \"your question\", \"answer\": \"your answer\"}]}, {\"content\": \"{\\\"questions\\\": [{\\\"question\\\": \\\"your question\\\", \\\"answer\\\": \\\"your answer\\\"}]}\", \"role\": \"user\", \"name\": \"user_agent\"}, {\"content\": \"Thank you for calling the contact center. This is AICCI.\\n\\nBefore we begin, please know that you will need to remain on the line until we've completed the entire interview process to ensure Amazon is able to address your concern as warranted. At the end of this process, I will provide you with a report key so you may follow up on this report. Do you wish to proceed?\\n\\nDo you work (or did you work) for a DSP Company (or Business) that delivers packages for Amazon? (DSP driver)\", \"role\": \"user\", \"name\": \"guidelines_agent\"}, {\"questions\": [{\"question\": \"Thank you for calling the contact center. This is AICCI.?\", \"answer\": \"\"}, {\"question\": \"Before we begin, please know that you will need to remain on the line until we've completed the entire interview process to ensure Amazon is able to address your concern as warranted. At the end of this process, I will provide you with a report key so you may follow up on this report. Do you wish to proceed?\", \"answer\": \"Yes please\"}, {\"question\": \"Do you work (or did you work) for a DSP Company (or Business) that delivers packages for Amazon? (DSP driver)?\", \"answer\": \"Yes\"}]}, {\"content\": \"{\\\"questions\\\": [{\\\"question\\\": \\\"Thank you for calling the contact center. This is AICCI.?\\\", \\\"answer\\\": \\\"\\\"}, {\\\"question\\\": \\\"Before we begin, please know that you will need to remain on the line until we've completed the entire interview process to ensure Amazon is able to address your concern as warranted. At the end of this process, I will provide you with a report key so you may follow up on this report. Do you wish to proceed?\\\", \\\"answer\\\": \\\"Yes please\\\"}, {\\\"question\\\": \\\"Do you work (or did you work) for a DSP Company (or Business) that delivers packages for Amazon? (DSP driver)?\\\", \\\"answer\\\": \\\"Yes\\\"}]}\", \"role\": \"user\", \"name\": \"user_agent\"}, {\"content\": \"Do you deliver packages on road for Amazon either through the DSP, FLEX, HUB Program and Walker Program?\", \"role\": \"user\", \"name\": \"guidelines_agent\"}, {\"questions\": [{\"question\": \"Do you deliver packages on road for Amazon either through the DSP, FLEX, HUB Program and Walker Program?\", \"answer\": \"No\"}]}, {\"content\": \"{\\\"questions\\\": [{\\\"question\\\": \\\"Do you deliver packages on road for Amazon either through the DSP, FLEX, HUB Program and Walker Program?\\\", \\\"answer\\\": \\\"No\\\"}]}\", \"role\": \"user\", \"name\": \"user_agent\"}, {\"content\": \"Do you or have you ever delivered packages for Amazon?\", \"role\": \"user\", \"name\": \"guidelines_agent\"}, {\"questions\": [{\"question\": \"Do you or have you ever delivered packages for Amazon?\", \"answer\": \"No\"}]}]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: router_agent\n",
      "\u001b[0m\n",
      "\u001b[33mrouter_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "{\"action\":\"main_guidelines\"}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "{\"questions\": [{\"question\": \"Do you or have you ever delivered packages for Amazon?\", \"answer\": \"No\"}]}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: guidelines_agent\n",
      "\u001b[0m\n",
      "\u001b[33mguidelines_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "If the caller has reached the correct line, click here to file a new report.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "{\"questions\": [{\"question\": \"If the caller has reached the correct line, click here to file a new report.?\", \"answer\": \"\"}]}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please provide data in JSON format (e.g. {\"questions\": [{\"question\": \"your question\", \"answer\": \"your answer\"}]}):  {\"questions\": [{\"question\": \"If the caller has reached the correct line, click here to file a new report.?\", \"answer\": \"I cant click\"}]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mmemory_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "[{}, {\"questions\": [{\"question\": \"your question\", \"answer\": \"your answer\"}]}, {\"content\": \"{\\\"questions\\\": [{\\\"question\\\": \\\"your question\\\", \\\"answer\\\": \\\"your answer\\\"}]}\", \"role\": \"user\", \"name\": \"user_agent\"}, {\"content\": \"Thank you for calling the contact center. This is AICCI.\\n\\nBefore we begin, please know that you will need to remain on the line until we've completed the entire interview process to ensure Amazon is able to address your concern as warranted. At the end of this process, I will provide you with a report key so you may follow up on this report. Do you wish to proceed?\\n\\nDo you work (or did you work) for a DSP Company (or Business) that delivers packages for Amazon? (DSP driver)\", \"role\": \"user\", \"name\": \"guidelines_agent\"}, {\"questions\": [{\"question\": \"Thank you for calling the contact center. This is AICCI.?\", \"answer\": \"\"}, {\"question\": \"Before we begin, please know that you will need to remain on the line until we've completed the entire interview process to ensure Amazon is able to address your concern as warranted. At the end of this process, I will provide you with a report key so you may follow up on this report. Do you wish to proceed?\", \"answer\": \"Yes please\"}, {\"question\": \"Do you work (or did you work) for a DSP Company (or Business) that delivers packages for Amazon? (DSP driver)?\", \"answer\": \"Yes\"}]}, {\"content\": \"{\\\"questions\\\": [{\\\"question\\\": \\\"Thank you for calling the contact center. This is AICCI.?\\\", \\\"answer\\\": \\\"\\\"}, {\\\"question\\\": \\\"Before we begin, please know that you will need to remain on the line until we've completed the entire interview process to ensure Amazon is able to address your concern as warranted. At the end of this process, I will provide you with a report key so you may follow up on this report. Do you wish to proceed?\\\", \\\"answer\\\": \\\"Yes please\\\"}, {\\\"question\\\": \\\"Do you work (or did you work) for a DSP Company (or Business) that delivers packages for Amazon? (DSP driver)?\\\", \\\"answer\\\": \\\"Yes\\\"}]}\", \"role\": \"user\", \"name\": \"user_agent\"}, {\"content\": \"Do you deliver packages on road for Amazon either through the DSP, FLEX, HUB Program and Walker Program?\", \"role\": \"user\", \"name\": \"guidelines_agent\"}, {\"questions\": [{\"question\": \"Do you deliver packages on road for Amazon either through the DSP, FLEX, HUB Program and Walker Program?\", \"answer\": \"No\"}]}, {\"content\": \"{\\\"questions\\\": [{\\\"question\\\": \\\"Do you deliver packages on road for Amazon either through the DSP, FLEX, HUB Program and Walker Program?\\\", \\\"answer\\\": \\\"No\\\"}]}\", \"role\": \"user\", \"name\": \"user_agent\"}, {\"content\": \"Do you or have you ever delivered packages for Amazon?\", \"role\": \"user\", \"name\": \"guidelines_agent\"}, {\"questions\": [{\"question\": \"Do you or have you ever delivered packages for Amazon?\", \"answer\": \"No\"}]}, {\"content\": \"{\\\"questions\\\": [{\\\"question\\\": \\\"Do you or have you ever delivered packages for Amazon?\\\", \\\"answer\\\": \\\"No\\\"}]}\", \"role\": \"user\", \"name\": \"user_agent\"}, {\"content\": \"If the caller has reached the correct line, click here to file a new report.\", \"role\": \"user\", \"name\": \"guidelines_agent\"}, {\"questions\": [{\"question\": \"If the caller has reached the correct line, click here to file a new report.?\", \"answer\": \"I cant click\"}]}]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: router_agent\n",
      "\u001b[0m\n",
      "\u001b[33mrouter_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "{\"action\":\"main_guidelines\"}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "{\"questions\": [{\"question\": \"If the caller has reached the correct line, click here to file a new report.?\", \"answer\": \"I cant click\"}]}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: guidelines_agent\n",
      "\u001b[0m\n",
      "\u001b[33mguidelines_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "Since you have not delivered packages for Amazon, I am unable to proceed with filing a report. If you have any other concerns or need assistance with a different matter, please let me know. Thank you for calling.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "{\"questions\": [{\"question\": \"Since you have not delivered packages for Amazon, I am unable to proceed with filing a report. If you have any other concerns or need assistance with a different matter, please let me know. Thank you for calling.?\", \"answer\": \"\"}]}\n"
     ]
    }
   ],
   "source": [
    "def detect_action():\n",
    "    memory = read_chat_history()\n",
    "    new_message = collect_json_data()\n",
    "    memory.append(new_message)\n",
    "\n",
    "    last_message = json.dumps(memory)\n",
    "    history = memory_agent.initiate_chat(recipient=manager_router, message=last_message, clear_history=False)\n",
    "    message = history.chat_history[-1][\"content\"]\n",
    "    last_message = json.loads(message)\n",
    "    action = last_message.get(\"action\", None)\n",
    "\n",
    "    return action, new_message \n",
    "\n",
    "def process_action(action, new_message):\n",
    "    if action == \"main_guidelines\":\n",
    "        return main_guidelines(new_message)\n",
    "    else:\n",
    "        print(f\"Invalid action: {action}\")\n",
    "        return {\"error\": \"Invalid action\"}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        action, new_message = detect_action()\n",
    "        process_action(action, new_message)\n",
    "        if action == \"terminate_chat\":\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57134f0a-93cf-4858-9ce2-8a7a6f7ad10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"memory.json\", \"r\") as json_file:\n",
    "    chat_history_guidelines = json.load(json_file)\n",
    "print(json.dumps(chat_history_guidelines, indent=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
